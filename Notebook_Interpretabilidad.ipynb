{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM1ofgcvsJKAPUhEOxURrYE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrodriguezru/ML-Interpretability/blob/main/Notebook_Interpretabilidad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretabilidad de Modelos de Machine Learning\n",
        "\n",
        "Los modelos de machine learning normalmente son contemplados como \"cajas negras\" en donde no se sabe con certeza la importancia y el peso de cada variable en el resultado del modelo tanto para observaciones individuales, como para dar una explicación general del modelo.\n",
        "\n",
        "Este notebook está diseñado para dar una aproximación a la librería *shap*, la cual provee múltiples *Explainers* para diferentes tipos de modelos de machine learning y con la que se puede hacer diferentes tipos de gráficas que explican dichos modelos.\n",
        "\n",
        "Se explorará la librería usando dos modelos que se adaptan a dos datasets diferentes para mostrar la importancia de ajustar las escalas para que la interpretabilidad sea desarrollada correctamente.\n",
        "\n",
        "Este notebook usa *Keras - TensorFlow* para lo cual, asegúrese que ha seleccionado **GPU T4** como **tipo de entorno de ejecución** en la configuración de la sesión de Google Colab.\n",
        "\n",
        "**Este notebook está diseñado con funcionalidades de autocalificación. Para el correcto funcionamiento, solo escriba su código  dentro de los espacios marcados para ello.**\n",
        "\n",
        "## Contenidos\n",
        "\n",
        "- [0 - Configuración de Google Colab](#0)\n",
        "- [1 - Paquetes](#1)\n",
        "- [2 - Funciones Auxiliares](#2)\n",
        "- [3 - Modelo de clasificación](#3)\n",
        "    - [3.1 - Exploración Inicial del Dataset y Pre-Procesamiento](#3-1)\n",
        "    - [3.2 - Construcción y Entrenamiento del Modelo](#3-2)\n",
        "    - [3.3 - SHAP y Explainers](#3-3)\n",
        "    - [3.4 - Gráficas Locales](#3-4)\n",
        "    - [3.5 - Gráficas Globales](#3-5)\n",
        "- [4 - Modelo de Regresión](#4)\n",
        "    - [4.1 - Exploración Inicial del Dataset y Pre-Procesamiento](#4-1)\n",
        "    - [4.2 - Construcción y Entrenamiento del Modelo](#4-2)\n",
        "    - [4.3 - SHAP y Explainers](#4-3)\n",
        "    - [4.4 - Gráficas Locales](#4-4)\n",
        "    - [4.5 - Gráficas Globales](#4-5)\n",
        "- [5 - Hazlo Tu Mismo (Ungraded)](#5)\n",
        "- [6 - Bibliografía](#6)\n",
        "\n"
      ],
      "metadata": {
        "id": "qp2eOt-G9yFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='0'></a>\n",
        "## 0 - Configuración de Google Colab\n",
        "\n",
        "Asegúrese que la carpeta que se incluye con este notebook sea guardada dentro de **Mi Unidad** en su cuenta de Google Drive. Ejecute la siguiente celda y acceda a su cuenta, dando los permisos necesarios. Esto hará que este notebook tenga acceso a los archivos necesarios para la autocalificación."
      ],
      "metadata": {
        "id": "6TCcpasl_1Ew"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA4qU1OR9RYN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/labInterpretability"
      ],
      "metadata": {
        "id": "rSmA2yUBAZJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='1'></a>\n",
        "## 1 - Paquetes Necesarios\n",
        "\n",
        "La siguiente celda importa todas las librerías necesarias para que este notebook funcione correctamente."
      ],
      "metadata": {
        "id": "ckKRvAmMAgJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ipywidgets\n",
        "%pip install colorama\n",
        "import shap\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers import Dense, Dropout, Embedding, Flatten, Input, concatenate\n",
        "from keras.models import Model\n",
        "import keras\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import pytest\n",
        "import tests\n",
        "from question_bank import display_question\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)"
      ],
      "metadata": {
        "id": "cPG4d74mBLcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente celda configura TensorFlow y Keras para que se use la GPU disponible. Asegúrese que ha seleccionado **GPU T4** como **tipo de entorno de ejecución** en la configuración de la sesión de Google Colab."
      ],
      "metadata": {
        "id": "Q5V4dEmXBabH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available\n",
        "gpu_available = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "if gpu_available:\n",
        "    print(\"GPU está disponible. Usando GPU.\")\n",
        "    # Set TensorFlow to use the GPU\n",
        "    tf.config.experimental.set_visible_devices(gpu_available[0], 'GPU')\n",
        "else:\n",
        "    print(\"No se encontró GPU. Usando CPU.\")"
      ],
      "metadata": {
        "id": "tWkuE6jTBRFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='2'></a>\n",
        "## 2 - Funciones Auxiliares\n",
        "\n",
        "Se usará una función auxiliar para todos los modelos:\n",
        "- Una función que encapsula un paso del preprocesamiento de los datos, más especificamente aplicando normalización."
      ],
      "metadata": {
        "id": "ZTQ3o06dGs1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x_train):\n",
        "  nn_preprocessor = MinMaxScaler(feature_range=(-1, 1))\n",
        "  X_train = nn_preprocessor.fit_transform(x_train)\n",
        "  return X_train"
      ],
      "metadata": {
        "id": "kWoYY6imHPzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Modelo de Clasificación\n",
        "\n",
        "El dataset para esta sección relaciona algunos datos de vehículos y sus dueños y lo relaciona con el número de veces que el dueño ha hecho reclamos al seguro."
      ],
      "metadata": {
        "id": "uEdNWi4JCkhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet('df.parquet')\n",
        "df"
      ],
      "metadata": {
        "id": "WTzkhbejFZC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Almacenamos los nombres de las columnas en las variables x y y\n",
        "y, x = df.columns[-1], list(df.columns[:-1])"
      ],
      "metadata": {
        "id": "tKQmGEKHIgnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3-1'></a>\n",
        "### 3.1 - Exploración del Dataset y Pre-Procesamiento\n",
        "\n",
        "Una buena práctica antes de iniciar con la construcción de modelos, es hacer un breve análisis del dataset. La siguiente celda da un resumen de los datos del dataframe."
      ],
      "metadata": {
        "id": "CmX7zSHbFEE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "rHwnmvO-FUBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El primer paso del preprocesamiento es dividir los datos en train y test. Para esto usaremos la función `train_test_split`incluida en la librería `sklearn`. Haremos una división 90% train, 10% test.\n",
        "\n"
      ],
      "metadata": {
        "id": "Z7Q8ym2YGKpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.1, random_state=30)"
      ],
      "metadata": {
        "id": "r3A6uCgSGKL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train.drop('claim_nb', axis=1)\n",
        "y_train = train['claim_nb']\n",
        "x_test = test.drop('claim_nb', axis=1)\n",
        "y_test = test['claim_nb']"
      ],
      "metadata": {
        "id": "AqlgoN8zIc2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente paso es hacer una normalización de los datos, para asegurarnos que los valores de todas las variables estén dentro del intervalo $(-1, 1)$. Esto ayuda con la estabilidad numérica y para prevenir que algunos pesos sean demasiado grandes o demasiado pequeños.\n",
        "\n",
        "La siguiente celda aplica la normalización al train set usando la función auxiliar que definimos anteriormente."
      ],
      "metadata": {
        "id": "xe70UEA7k3pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = normalize(x_train)"
      ],
      "metadata": {
        "id": "vb1ySo2elURn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3-2'></a>\n",
        "### 3.2 - Construcción y entrenamiento del modelo.\n",
        "\n",
        "La configuración del modelo para este dataset es la siguiente:\n",
        "- Primera capa oculta con 64 neuronas\n",
        "- Tres capas ocultas con 32 neuronas\n",
        "\n",
        "Las capas ocultas tienen función de activación `tanh`\n",
        "La capa de salida tiene función de activación `exponential`\n",
        "\n",
        "Se usará *Adam* como optimizador y la función de pérdida `poisson`"
      ],
      "metadata": {
        "id": "FpVI4iriIqzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input layer\n",
        "input_layer = Input(shape=(x_train.shape[1],)) # Adjust input shape to match the data's features\n",
        "\n",
        "# Add hidden layers\n",
        "hidden_layer_1 = Dense(64, activation='tanh')(input_layer) # Example number of neurons\n",
        "hidden_layer_2 = Dense(32, activation='tanh')(hidden_layer_1) # Example additional layer\n",
        "hidden_layer_3 = Dense(32, activation='tanh')(hidden_layer_2) # Layer 3\n",
        "hidden_layer_4 = Dense(32, activation='tanh')(hidden_layer_3) # Layer 4\n",
        "\n",
        "# Add the output layer\n",
        "output_layer = Dense(1, activation='exponential')(hidden_layer_4)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', # Specify optimizer\n",
        "              loss='poisson')\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ON2ySwCGJGVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora se entrena el modelo.\n",
        "\n",
        "Sin embargo, para asegurarnos que la autocalificabilidad funcione correctamente, se va a cargar un modelo pre-entrenado. En caso de querer entrenar el modelo, basta con comentar la segunda linea y des-comentar la primera linea de la siguiente celda."
      ],
      "metadata": {
        "id": "h04-3w9ZKIDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(X_train, y_train, epochs=5)\n",
        "model = keras.saving.load_model(\"model1.keras\")"
      ],
      "metadata": {
        "id": "Nq2ZJeBNKG7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3-3'></a>\n",
        "### 3.3 - SHAP y Explainers\n",
        "\n",
        "En este notebook se describen los métodos de interpretabilidad proporcionados por la librería SHAP. Esta librería se basa en la teoría de juegos cooperativo, en donde a cada jugador se le asigna un valor de su contribución al resultado final del juego.\n",
        "\n",
        "En Aprendizaje de Máquina, cada jugador corresponde a cada feature o componente de la variable de entrada y el resultado final del juego, sería la predicción del modelo.\n",
        "\n",
        "La teoría de SHAP propone que la forma \"justa\" de asignar las contribuciones de cada componente es aquella que cumpla los sigueintes axiomas."
      ],
      "metadata": {
        "id": "zyg58OELKLa9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sean $M={1, \\dots, p}$ los componentes de la variable de entrada, con $p\\in\\mathbb{N},p\\geq1$ y sea $c$ la predicción del modelo. Supongamos que la predicción para un subconjujnto de features $\\mathcal{L} \\subseteq M$ es dada por la función:\n",
        "$$v: \\mathcal{L} \\rightarrow v(\\mathcal{L}) \\in \\mathbb{R}$$\n",
        "\n",
        "Luego los axiomas son los siguentes:\n",
        "\n",
        "1. Eficiencia: La suma de todas las contribuciones, más un valor base, es igual a la contribución total. Esto es, $v(M) = \\sum_{i=0}^p \\phi_j^{(v)}$, donde $\\phi_0^{(v)}$ denota el valor base, el cual puede ser igual a $0$.\n",
        "2. Simetría: Si $v(\\mathcal{L}\\cup \\{j\\})=v(\\mathcal{L}\\cup \\{k\\})$ para todo $\\mathcal{L} \\subseteq M \\backslash \\{j,k\\}$, entonces $\\phi_j = \\phi_k$. Es decir, si para todo subconjunto de features posible que no incluya a los features $j$ y $k$, (matemáticamente, cualquier subconjunto del conjunto de features quitando los features $j$ y $k$), el valor de la contribución total del subconjunto incluyendo a $j$ es igual a aquel que incluye a $k$.\n",
        "3. Jugador nulo: Si $v(\\mathcal{L}\\cup\\{j\\}) = v(\\mathcal{L})$, para toda agrupación de features $\\mathcal{L}\\subseteq M \\backslash\\{j\\}$, entonces $\\phi_j=0$. Es decir, si para todo subconjunto de features, la contribución total no cambia al agregar al feature $j$, entonces la contribución del feature $j$ es igual a 0.\n",
        "4. Linealidad: Considere dos modelos con funciones de contribución total $v$ y $w$. Entonces, $\\phi_j^{(v+w)}=\\phi_j^{(v)} + \\phi_j^{(w)}$ y también $\\phi_j^{(\\alpha v)} = \\alpha\\phi_j^{(v)}$, para todo $1\\leq j \\leq p$ y $\\alpha \\in \\mathbb{R}$."
      ],
      "metadata": {
        "id": "y0BV4AW1and7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los valores de SHAP son precisamente aquellos números reales que cumplen estos axiomas y están dados por la siguiente fórmula:\n",
        "\n",
        "$$ \\phi_j = \\phi_j^{(v)} = \\sum_{\\mathcal{L}\\subseteq M \\backslash \\{j\\}} \\frac{|\\mathcal{L}|!(p-|\\mathcal{L}|-1)!}{p!}\\left[v\\left(\\mathcal{L}\\cup \\{j\\} \\right)- v\\left(\\mathcal{L}\\right)\\right] $$\n",
        "\n",
        "El primer factor es conocido como el peso de Shapley y el segundo factor es precisamente la contribución del feature $j$.\n",
        "\n",
        "Esta fórmula, se puede calcular de forma equivalente usando permutaciones mediante la siguiente fórmula:\n",
        "\n",
        "$$ \\phi_j = \\phi_j^{(v)} = \\frac{1}{p!} \\sum_{\\pi \\in S_p} \\left[v\\left(\\mathcal{L}_\\pi \\cup \\{j\\} \\right)- v\\left(\\mathcal{L}_\\pi \\right)\\right] $$\n",
        "\n",
        "Donde $\\mathcal{L}_\\pi \\in \\mathcal{M} \\backslash \\{j\\}$ denota el subconjunto de todos los predecesores del índice $j$ en la permutación $\\pi$.\n",
        "\n",
        "El costo computacional del cálculo de estos valores es alto, por lo que la librería emplea diferentes mecanismos como aproximación numérica para hallarlos además de contemplar y aprovechar de la arquitectura del modelo en cuestión para hallar los valores de una manera más eficiente."
      ],
      "metadata": {
        "id": "xdjfuarbb9-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La librería SHAP usa *Explainers* para calcular los valores SHAP. La librería tiene una variada selección de *Explainers*. Varios son *model agnostic* lo cual significa que funcionan para cualquier modelo, pero otros están diseñados específicamente para un tipo de modelo particular.\n",
        "\n",
        "Algunos de estos *Explainers* son:\n",
        "- ExactExplainer\n",
        "- PermutationExplainer\n",
        "- KernelExplainer\n",
        "- DeepExplainer\n",
        "\n",
        "La elección del *Explainer* no sólo determina la forma computacional en la que los valores SHAP son calculados, sino también la disponibilidad de algunas gráficas."
      ],
      "metadata": {
        "id": "kGohuc4QZZTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('shap_axioms')"
      ],
      "metadata": {
        "id": "zKfobjhaDVsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como este modelo es de clasificación, para poder \"aumentar\" las pequeñas variaciones que el modelo produce, se debe usar la escala logaritmica. La siguiente función encapsula los siguientes pasos en una sola función:\n",
        "1. Normalizar los datos de entrada.\n",
        "2. Hacer inferencia usando el modelo entrenado\n",
        "3. Aplicar escala logarítmica\n",
        "\n",
        "Esta función encapsuladora será la que se le pasa al *Explainer* de SHAP."
      ],
      "metadata": {
        "id": "Gwnt-cI5L2hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_predict(X):\n",
        "  df_scaled = normalize(X)\n",
        "  pred = model.predict(df_scaled, verbose=0, batch_size=10_000).flatten()\n",
        "  return np.log(pred)"
      ],
      "metadata": {
        "id": "c9G_ahfvJ-hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una de las maneras de elegir un *Explainer* adecuado, es usando la clase `Explainer`que tiene la librería. Esta clase analiza la variable de entrada y la arquitectura de la función o mdelo que recibe para elegir un *Explainer* adecuado.\n",
        "\n",
        "En la siguiente celda, se usa la clase `Explainer`, la cual recibe la función `nn_predict`como `model`."
      ],
      "metadata": {
        "id": "X4JFnrGrMz5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(model=nn_predict, masker=X_train)"
      ],
      "metadata": {
        "id": "j-o9hxiKMzeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando `__class__` podemos ver el *Explainer* concreto que SHAP eligió para el modelo."
      ],
      "metadata": {
        "id": "rCdBn_-8OIrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer.__class__"
      ],
      "metadata": {
        "id": "uLghjKJsOYOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, la librería elige el `ExactExplainer` para el cálculo de los valores de SHAP.\n",
        "\n",
        "Este `Explainer` es eficiente para calcular los valores de SHAP para aquellos modelos que tienen menos de $15$ features. Este `Explainer` reduce la cantidad de llamadas a la función de evaluación ordenando los datos para reducir las diferencias secuenciales."
      ],
      "metadata": {
        "id": "QxVRH0X0fUqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, se deben calcular los valores SHAP para una o múltiples observaciones. Para ello se usa el `explainer`quien recibe los datos de entrada del modelo y se devuelven los valores de SHAP para cada observación.\n",
        "\n",
        "Este proceso es bastante demandante computacionalmente, por lo tanto, sólamente se va a pasar una **fracción** del **test set** para el cálculo de los valores SHAP.\n",
        "\n",
        "Para este caso, se usarán únicamente los primeros 1000 datos del set de prueba."
      ],
      "metadata": {
        "id": "Vtra0GGZOVTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ESCRIBA SU CÓDIGO AQUI (~ 1 linea)\n",
        "\n",
        "## FIN DE SU CÓDIGO"
      ],
      "metadata": {
        "id": "nCOwhPflPARX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3-4'></a>\n",
        "### 3.4 - Gráficas Locales\n",
        "\n",
        "SHAP ofrece la posibilidad de analizar el peso e importancia de las entradas de una observación específica.\n",
        "\n",
        "Para este modelo, se explorarán dos gráficas para esto:\n",
        "- Waterfall\n",
        "- ForcePlot\n",
        "\n",
        "Ambas gráficas están centradas en un *valor base*, el cual formalmente es el valor esperado del modelo. Sin embargo, este *valor base* se puede calcular como el promedio aritmético de los valores de las predicciones que el *Explainer* recibe.\n",
        "\n",
        "Dependiendo el tipo de modelo que se use, existen otras gráficas que se pueden usar. Por ejemplo, en aquellos modelos en los que se analiza una imágen como entrada, existe una gráfica que muestra detalles específicos de la imágen que hacen que afecte la predicción del modelo."
      ],
      "metadata": {
        "id": "fS6xES2oPDGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Waterfall\n",
        "\n",
        "Para generar la gráfica de tipo **Waterfall** se requiere llamar a la función `shap.plots.waterfall` pasando los valores de SHAP de la observación. Para este ejemplo usaremos los valores de SHAP almacenados en el índice 0.\n",
        "\n",
        "Para que el autocalificador funcione correctamente, hay que agregar `show=False`dentro de los argumentos de la función. Esto hace que la gráfica no se muestre inmediatamente y sea posible hacer ajustes a la gráfica y/o guardarla en un archivo.\n",
        "La linea `plt.show()`es la encargada de mostrar la gráfica."
      ],
      "metadata": {
        "id": "HbY-XkMRPg3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ESCRIBA SU CÓDIGO AQUI (~ 1 linea)\n",
        "\n",
        "## FIN DE SU CÓDIGO\n",
        "\n",
        "plt.savefig('generated_images/waterfall_1.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Eyu58zGsPqfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests.test_waterfall_plot_classification()"
      ],
      "metadata": {
        "id": "NYcyJCFEx6EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ForcePlot\n",
        "\n",
        "Esta gráfica requiere JavaScript para funcionar, por lo tanto se inicializa mediante la función `shap.initjs()`.\n",
        "\n",
        "Para generar la gráfica, se llama a la función `shap.plots.force` pasando los valores de SHAP de la observación. Igual que en la gráfica de tipo Waterfall, usaremos los valores de SHAP almacenados en el índice 0."
      ],
      "metadata": {
        "id": "mMICH9_qP39d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "shap.plots.force(shap_values[0])"
      ],
      "metadata": {
        "id": "23quR5mQQeC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede observar, ambas gráficas muestran la misma información de una manera distinta. Sin embargo, podemos ver las variables que hacen que la predicción del modelo aumente representadas con el color rosado-rojo y las variables que hacen que la predicción del modelo disminuya representadas con el color azul. También se puede apreciar el peso de cada variable en la predicción final del modelo."
      ],
      "metadata": {
        "id": "nqvCafawQfzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('wat_class_0')"
      ],
      "metadata": {
        "id": "1rvGi5MIcLqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('wat_class_1')"
      ],
      "metadata": {
        "id": "BdwCGPe4cMNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('wat_class_2')"
      ],
      "metadata": {
        "id": "XeykUbS3cMn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3-5'></a>\n",
        "### 3.5 - Gráficas Globales\n",
        "\n",
        "SHAP también ofrece la posibilidad de analizar el peso e importancia de las variables de entrada en el modelo de forma general.\n",
        "\n",
        "Existen múltiples gráficas disponibles dependiendo del modelo. Para este modelo particular, se explorarán las siguientes gráficas:\n",
        "\n",
        "- Bar\n",
        "- Beeswarm"
      ],
      "metadata": {
        "id": "HiHwdOR-Rtek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bar\n",
        "\n",
        "Para generar la gráfica de tipo **Bar** se requiere llamar a la función `shap.plots.bar` pasando todos los valores de SHAP disponibles.\n",
        "\n",
        "Para que el autocalificador funcione correctamente, hay que agregar `show=False`dentro de los argumentos de la función. Esto hace que la gráfica no se muestre inmediatamente y sea posible hacer ajustes a la gráfica y/o guardarla en un archivo.\n",
        "La linea `plt.show()`es la encargada de mostrar la gráfica."
      ],
      "metadata": {
        "id": "4LpL-9i_dVJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ESCRIBA SU CÓDIGO AQUI (~ 1 linea)\n",
        "\n",
        "## FIN DE SU CÓDIGO\n",
        "\n",
        "plt.savefig('generated_images/bar_1.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D0pMfr__dzHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests.test_bar_plot_classification()"
      ],
      "metadata": {
        "id": "H-XPEqeI-T3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta gráfica muestra un promedio de la contribución de cada componete (el promedio de su valor de SHAP). En general, si el valor es positivo y la barra es de color rosado-rojo, esto indica que este componente hace que la predicción aumente. En caso contrario, si el valor es negativo y la barra es de color azul, el componente hace que la predicción disminuya."
      ],
      "metadata": {
        "id": "pq4kHt2Pd0j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('bar_class_0')"
      ],
      "metadata": {
        "id": "x3M7Q30WccCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Beeswarm\n",
        "\n",
        "Para generar la gráfica de tipo **Beeswarm** se requiere llamar a la función `shap.plots.beeswarm` pasando todos los valores de SHAP disponibles.\n",
        "\n",
        "Para que el autocalificador funcione correctamente, hay que agregar `show=False`dentro de los argumentos de la función. Esto hace que la gráfica no se muestre inmediatamente y sea posible hacer ajustes a la gráfica y/o guardarla en un archivo.\n",
        "La linea `plt.show()`es la encargada de mostrar la gráfica."
      ],
      "metadata": {
        "id": "U4p13wt9eR64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ESCRIBA SU CÓDIGO AQUI (~ 1 linea)\n",
        "\n",
        "## FIN DE SU CÓDIGO\n",
        "\n",
        "plt.savefig('generated_images/beeswarm_1.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y2ZUSp8veRfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests.test_beeswarm_plot_classification()"
      ],
      "metadata": {
        "id": "FJmFmT-3-diY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta gráfica brinda bastante información pues nos muestra la distribución de las contribuciones (eje X) de cada componente (eje Y) de acuerdo a su valor real (color de cada punto). Cada punto correspode a una observación particular para el que se le calcularon sus valores de SHAP."
      ],
      "metadata": {
        "id": "0qHfHSpaeiXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('beeswarm_class_0')"
      ],
      "metadata": {
        "id": "LAGR8Hafce8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('beeswarm_class_1')"
      ],
      "metadata": {
        "id": "QI-Lc89_cfSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4'></a>\n",
        "## 4 - Modelo de regresión\n",
        "\n",
        "El dataset para esta sección relaciona algunos datos médicos de personas y el costo de su seguro médico.\n"
      ],
      "metadata": {
        "id": "xAh1LfOXgPsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"insurance.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "opMh46lphVG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Almacenamos los nombres de las columnas en las variables x y y\n",
        "y, x = df.columns[-1], list(df.columns[:-1])"
      ],
      "metadata": {
        "id": "3IyQ7d50himM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4-1'></a>\n",
        "### 4.1 - Exploración del Dataset y Pre-Procesamiento\n",
        "\n",
        "La siguiente celda da un resumen de los datos del dataframe."
      ],
      "metadata": {
        "id": "YCJ4JcVsgcIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "02u6OqYdhzmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El primer paso del preprocesamiento es dividir los datos en train y test. Para esto usaremos la función`train_test_split` incluida en la librería `sklearn`. Haremos una división 90% train, 10% test."
      ],
      "metadata": {
        "id": "NTG1_Lf2iJxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.1, random_state=30)"
      ],
      "metadata": {
        "id": "ZeX9c839h9am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train.drop('charges', axis=1)\n",
        "y_train = train['charges']\n",
        "x_test = test.drop('charges', axis=1)\n",
        "y_test = test['charges']"
      ],
      "metadata": {
        "id": "vQavu5LbiXBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como este dataset tiene columnas con datos categóricos, hay que codificar esta información en algún formato numérico, para lo cual se usará One-Hot Encoding. En este caso, vamos a usar la función de `Pandas`, `pd.get_dummies` la cual aplica One-Hot Encoding a las variables especificadas. Esta función lo que hace es para cada variable, si esta es binaria, el nuevo nombre es la variable original seguido por la primera categoría; si la variable no es binaria, se hace una nueva columna por cada categoría. La siguiente celda aplica One-Hot Encoding tanto al train set como al test set."
      ],
      "metadata": {
        "id": "XeAn8R4ZiYnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = pd.get_dummies(x_train, columns=['sex', 'smoker', 'region'], drop_first=True, dtype=float)\n",
        "x_test = pd.get_dummies(x_test, columns=['sex', 'smoker', 'region'], drop_first=True, dtype=float)\n",
        "\n",
        "# Ensure columns are aligned between train and test sets after one-hot encoding\n",
        "train_cols = list(x_train.columns)\n",
        "test_cols = list(x_test.columns)\n",
        "\n",
        "for col in train_cols:\n",
        "    if col not in test_cols:\n",
        "        x_test[col] = 0\n",
        "for col in test_cols:\n",
        "    if col not in train_cols:\n",
        "        x_train[col] = 0\n",
        "\n",
        "x_test = x_test[train_cols] # Reorder test columns to match train columns"
      ],
      "metadata": {
        "id": "2uhexwn2jHqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente paso es aplicar una normalización para asegurarnos que los datos estén dentro del intervalo $(-1, 1)$. Esto ayuda con la estabilidad numérica y a mantener los pesos del modelo dentro de rangos numéricamente estables.\n",
        "\n",
        "La siguiente celda aplica la normalización que definimos anteriormente."
      ],
      "metadata": {
        "id": "Rf8CixDEliGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = normalize(x_train)"
      ],
      "metadata": {
        "id": "dqY4cyStlvgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4-2'></a>\n",
        "### 4.2 - Construcción y entrenamiento del modelo\n",
        "\n",
        "La arquitectura de este modelo es la siguente:\n",
        "\n",
        "- Primera capa oculta con 32 neuronas y función de activación `Relu`\n",
        "- Segunda capa oculta con 64 neuronas y función de activación `Relu\n",
        "- Capa de salida con función de activación lineal.\n",
        "\n",
        "- Se utiliza el optimizador `Adam`\n",
        "- Se utiliza la función de pérdida de mínimos cuadrados `mse`\n",
        "- Se utiliza la función de error absoluto medio `mae` como métrica."
      ],
      "metadata": {
        "id": "sbY6LDo3jTKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input layer\n",
        "input_layer = Input(shape=(x_train.shape[1],)) # Adjust input shape to match the data's features\n",
        "\n",
        "# Add hidden layers\n",
        "hidden_layer_1 = Dense(64, activation='relu')(input_layer) # Example number of neurons\n",
        "hidden_layer_2 = Dense(32, activation='relu')(hidden_layer_1) # Example additional layer\n",
        "\n",
        "# Add the output layer\n",
        "output_layer = Dense(1, activation='linear')(hidden_layer_2) # Output layer for regression, linear activation\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', # Specify optimizer\n",
        "              loss='mse', # Change loss function to Mean Squared Error for regression\n",
        "              metrics=['mae']) # Change metric to Mean Absolute Error for regression\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "42RvrKQZkE5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora se entrena el modelo.\n",
        "\n",
        "Sin embargo, para asegurarnos que la autocalificabilidad funcione correctamente, se va a cargar un modelo pre-entrenado. En caso de querer entrenar el modelo, basta con comentar la segunda linea y des-comentar la primera linea de la siguiente celda."
      ],
      "metadata": {
        "id": "FeLV4G84kLo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(x_train, y_train, epochs=5)\n",
        "model = keras.saving.load_model(\"model2.keras\")"
      ],
      "metadata": {
        "id": "cMQw0QfdkKG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4-3'></a>\n",
        "### 4.3 - SHAP y Explainers\n",
        "\n",
        "Como este modelo es de regresión, no es necesario aplicar escala logarítmica a las predicciones del modelo. Sin embargo, igual se deben normalizar los datos de prueba antes de ser enviados al modelo para la inferencia.\n",
        "\n",
        "La siguiente celda aplica la normalización."
      ],
      "metadata": {
        "id": "KgpCzUHwkOfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_predict(X):\n",
        "  df_scaled = normalize(X)\n",
        "  pred = model.predict(df_scaled, verbose=0, batch_size=10_000).flatten()\n",
        "  return pred"
      ],
      "metadata": {
        "id": "qLOvAmalm348"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la siguiente celda, se usa la clase Explainer, la cual recibe la función nn_predict como model."
      ],
      "metadata": {
        "id": "GTzohxKunELc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(model=nn_predict, masker=X_train)"
      ],
      "metadata": {
        "id": "GYN6zaOpnD-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando `__class__` podemos ver el `Explainer` que SHAP eligió para el modelo"
      ],
      "metadata": {
        "id": "sNQC3nBqnIWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer.__class__"
      ],
      "metadata": {
        "id": "opwmQ_menPmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos evidenciar que para este modelo también se eligió el `ExactExplainer`.\n",
        "\n",
        "Otros explainers que SHAP puede elegir (que también se pueden usar manualmente) son:\n",
        "- DeepExplainer: Optimizado para modelos de aprendizaje profundo. Es una versión mejorada de DeepLIFT (DeepSHAP) en donde los valores de SHAP son aproximados usando una selección de datos de muestra.\n",
        "- KernelExplainer: Este explainer puede ser usado para explicar cualquier función. Aproxima los valores de SHAP mediante una regresión lineal especial.\n",
        "- PermutationExplainer: Este explainer, el cual es model agnostic (es decir que funciona para cualquier mdoelo), aproxima los valores de SHAP mediante la iteración de múltiples permutaciones de los datos de entrada.\n",
        "- TreeExplainer: Este explainer está diseñado para los modelos basados en árboles. Este explainer usa múltiples suposiciones en cuanto a dependencia de features.\n",
        "\n",
        "\n",
        "Más información de los explainers se puede encontrar en la [documentación oficial de la librería](https://shap.readthedocs.io/en/latest/api.html#explainers)."
      ],
      "metadata": {
        "id": "KscZwUwRnWa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('explainer_choice')"
      ],
      "metadata": {
        "id": "eiMj0iYOc2Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, se deben calcular los valores SHAP para una o múltiples observaciones. Para ello se usa el explainer quièn recibe los datos de entrada del modelo y se devuelven los valores de SHAP para cada observación.\n",
        "\n",
        "Aunque este proceso es bastante demandante computacionalmente, el test set de este modelo es bastante pequeño, por lo que podemos calcular los valores de SHAP para todas las observaciones del test set."
      ],
      "metadata": {
        "id": "0BN6T2RZnV7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ESCRIBA SU CÓDIGO AQUI (~ 1 linea)\n",
        "\n",
        "## FIN DE SU CÓDIGO"
      ],
      "metadata": {
        "id": "77JHSexrnqs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4-4'></a>\n",
        "###4.4 - Gráficas Locales\n",
        "\n",
        "Para este modelo, se explorarán dos gráficas locales:\n",
        "\n",
        "- Waterfall\n",
        "- ForcePlot"
      ],
      "metadata": {
        "id": "kJRwXywUomDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Waterfall\n",
        "\n",
        "Para esta gráfica se debe pasar los valores de SHAP para una sóla observación. En este caso, se usarán los valores de SHAP almacenados en el índice $0$.\n",
        "\n",
        "Para que el autocalificador funcione correctamente, hay que agregar `show=False`dentro de los argumentos de la función. Esto hace que la gráfica no se muestre inmediatamente y sea posible hacer ajustes a la gráfica y/o guardarla en un archivo.\n",
        "La linea `plt.show()`es la encargada de mostrar la gráfica."
      ],
      "metadata": {
        "id": "7d_pq4o-owrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ESCRIBA SU CÓDIGO AQUI (~ 1 linea)\n",
        "\n",
        "## FIN DE SU CÓDIGO\n",
        "\n",
        "plt.savefig('generated_images/waterfall_2.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "axf5xYQGo1Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests.test_waterfall_plot_regression()"
      ],
      "metadata": {
        "id": "IiXzslJ6-g8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ForcePlot\n",
        "\n",
        "Esta gráfica requiere cargar JavaScript en la celda.\n",
        "\n",
        "Para esta gráfica se usarán los mismos valores de SHAP que la gráfica anterior."
      ],
      "metadata": {
        "id": "D-3yr1IwpD75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "shap.plots.force(shap_values[0])"
      ],
      "metadata": {
        "id": "ma1LhozOpSni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('wat_reg_0')"
      ],
      "metadata": {
        "id": "o1UNGbuBc7un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('wat_reg_1')"
      ],
      "metadata": {
        "id": "Y0_BhE7Rc8NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4-5'></a>\n",
        "###4.5 - Gráficas Globales\n",
        "\n",
        "Para este modelo, se explorarán las siguientes gráficas globales:\n",
        "\n",
        "- Bar\n",
        "- Beeswarm"
      ],
      "metadata": {
        "id": "ZkL1R3RBpcA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bar\n",
        "\n",
        "La gráfica de tipo **Bar** requiere todos los valores de SHAP disponibles.\n",
        "\n",
        "Para que el autocalificador funcione correctamente, hay que agregar `show=False`dentro de los argumentos de la función. Esto hace que la gráfica no se muestre inmediatamente y sea posible hacer ajustes a la gráfica y/o guardarla en un archivo.\n",
        "La linea `plt.show()`es la encargada de mostrar la gráfica."
      ],
      "metadata": {
        "id": "dvcVPgoupmW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ESCRIBA SU CÓDIGO AQUI (~ 1 linea)\n",
        "\n",
        "## FIN DE SU CÓDIGO\n",
        "\n",
        "plt.savefig('generated_images/bar_2.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-So624mKpxKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests.test_bar_plot_regression()"
      ],
      "metadata": {
        "id": "HlNdmeMV-pyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('bar_reg_0')"
      ],
      "metadata": {
        "id": "j4m5HXpWc85y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('bar_reg_1')"
      ],
      "metadata": {
        "id": "3mzGwn_Qc9P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Beeswarm\n",
        "\n",
        "La gráfica de tipo **Beeswarm** requiere todos los valores de SHAP disponibles.\n",
        "\n",
        "Para que el autocalificador funcione correctamente, hay que agregar `show=False`dentro de los argumentos de la función. Esto hace que la gráfica no se muestre inmediatamente y sea posible hacer ajustes a la gráfica y/o guardarla en un archivo.\n",
        "La linea `plt.show()`es la encargada de mostrar la gráfica."
      ],
      "metadata": {
        "id": "kmhB7Qb2pn7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ESCRIBA SU CÓDIGO AQUI (~ 1 linea)\n",
        "\n",
        "## FIN DE SU CÓDIGO\n",
        "\n",
        "plt.savefig('generated_images/beeswarm_2.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DpKdefABp4FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests.test_beeswarm_plot_regression()"
      ],
      "metadata": {
        "id": "-a6kyC0w-pMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('beeswarm_reg_0')"
      ],
      "metadata": {
        "id": "6QsM9i75c95F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_question('beeswarm_reg_1')"
      ],
      "metadata": {
        "id": "8ut90bhyc-Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='5'></a>\n",
        "##5 - Hazlo Tu Mismo (Ungraded)\n",
        "\n",
        "Para los siguientes datasets, sigue el mismo flujo que se ha trabajado en el notebook para poder hacer interpretabilidad del modelo que se entrenará.\n",
        "\n",
        "El siguiente dataset reúne transacciones con tarjetas de crédito que se realizaron en Europa en un fragmento de tiempo durante Septiembre de 2013. Casi toda la información está codificada, con excepción del valor de la compra, y el momento de la transacción. El objetivo es predecir si la transacción es fraudulenta."
      ],
      "metadata": {
        "id": "mRBqwVO2NY7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"creditcard_31ft.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "mLy6cfRnOg6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ESCRIBA SU CÓDIGO AQUI (Puede usar más celdas de código)\n",
        "\n"
      ],
      "metadata": {
        "id": "YTeeyDNURIXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente dataset reúne datos de vehiculos y sus propietarios en Estados Unidos. El objetivo es predecir si la persona hizo un reclamo a su seguro."
      ],
      "metadata": {
        "id": "aFf3NnOQUJMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Car_Insurance_Claim.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "t902tIjKVByz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ESCRIBA SU CÓDIGO AQUI (Puede usar más celdas de código)\n",
        "\n"
      ],
      "metadata": {
        "id": "TjT_tNr6U3uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='6'></a>\n",
        "##6 - Bibliografía\n",
        "- Actuarial-data-science/Tutorials: Code for the Actuarial Data Science Tutorials published at https://actuarialdatascience.org. https://github.com/actuarial-data-science/Tutorials/blob/master/14%20-%20SHAP/shap_tutorial.ipynb\n",
        "- Shap/Shap: A game theoretic approach to explain the output of any machine learning\n",
        "model. https://github.com/shap/shap?tab=readme-ov-file\n",
        "- Lundberg, Scott M. ; Lee, Su-In: A Unified Approach to Interpreting Model Predic-\n",
        "tions. Curran Associates, Inc., 2017\n",
        "- Mayer, Michael ; Meier, Daniel ; Wuthrich, Mario: SHAP for Actuaries: Explain\n",
        "any Model. En: SSRN Electronic Journal (2023), 03, p. 25\n",
        "- Nasteski, Vladimir: An overview of the supervised machine learning methods. En:\n",
        "HORIZONS.B 4 (2017), 12, p. 51–62\n",
        "- Ng, Andrew ; Ma, Tengyu. CS229 Lecture Notes. 2023\n",
        "- Norvig, Stuart J. Russell P.: Artificial Intelligence. A Modern Approach. Pearson,\n",
        "Upper Saddle River, 2020. – ISBN 978–0134610993\n",
        "- Yadav, Amit. SHAP Values Explained. https://medium.com/biased-algorithms/shap-values-explained-08764ab16466\n",
        "- Oliveira, Willian. Healthcare Insurance https://www.kaggle.com/datasets/willianoliveiragibin/healthcare-insurance?resource=download\n",
        "- Roy, Sagnik. Car Insurance Data https://www.kaggle.com/datasets/sagnik1511/car-insurance-data/data\n",
        "- ULB, Machine Learning G. Credit Card Fraud Detection https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data"
      ],
      "metadata": {
        "id": "2ARD_Z5kOssN"
      }
    }
  ]
}